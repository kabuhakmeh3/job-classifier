{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Naive Bayes vs Logistic Regression to classify job listings\n",
    "\n",
    "Understanding the availability of jobs is important in determining which positions to feature in ads, who to target, where to target them, and which platforms to target them on.\n",
    "\n",
    "As discussed in the Job Listing EDA notebook, labeling jobs by role or company can be error prone. Instead, learning patterns which are common in a certain type of job and applying a label automatically may be helpful. Especially when dealing with over 10M jobs each day. \n",
    "\n",
    "Here, we look at basic NLP approaches to classify jobs by title. For simplicity, we only consider whether a job is a skilled position (nurses, engineers, consultants) or a gig-role (drivers, cashiers, shoppers).\n",
    "\n",
    "We are primarily interested in identifying and isolating gig-jobs. These roles are more suitable for advertising through social media platforms and tend to have high click rates.\n",
    "\n",
    "Previously, we evaluated Logistic Regression. However, during that process, we noticed that certain words were almost guaranteed to impact the classification of a posting as a skilled or not. Naive Bayes offers several distinct benefits. First, it is easy to understand: a term has a probability of being associated with a particular label. Second, naive bayes is easy to train and can be used to apply multiple labels, given sufficient training examples for each label. Last, the model can continue to be re-trained as more labeled samples become available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'city', 'state', 'zip', 'country', 'posted_at',\n",
       "       'job_reference', 'company', 'category', 'body', 'gig'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/labeled_eda_sample_data_file.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>gig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail Store Manager - Alabaster AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial Relationship Consultant - Pell City</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prod Cook 3 PM Bob's Steak &amp; Chop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quant Developer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human Resource Manager</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  gig\n",
       "0            Retail Store Manager - Alabaster AL    0\n",
       "1  Financial Relationship Consultant - Pell City    0\n",
       "2              Prod Cook 3 PM Bob's Steak & Chop    1\n",
       "3                                Quant Developer    0\n",
       "4                         Human Resource Manager    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_train = ['title', 'gig'] \n",
    "data = data[cols_to_train]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cleanup text **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    '''Clean-up text column to prepare for tokenization\n",
    "    \n",
    "    Removes unwanted characters &\n",
    "    Replaces them with spaces or blanks\n",
    "    --\n",
    "    Input\n",
    "    + pandas dataframe\n",
    "    + name of text column\n",
    "    \n",
    "    Returns\n",
    "    + pandas dataframe with cleaned column\n",
    "    '''\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retail store manager   alabaster al</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financial relationship consultant   pell city</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod cook 3 pm bob's steak   chop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quant developer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human resource manager</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job_title  class_label\n",
       "0            retail store manager   alabaster al            0\n",
       "1  financial relationship consultant   pell city            0\n",
       "2              prod cook 3 pm bob's steak   chop            1\n",
       "3                                quant developer            0\n",
       "4                         human resource manager            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cols = ['title']\n",
    "\n",
    "for col in text_cols:\n",
    "    data = standardize_text(data, col)\n",
    "\n",
    "col_names = {'title':'job_title',\n",
    "             'gig':'class_label'}    \n",
    "\n",
    "data = data.rename(columns=col_names)\n",
    "\n",
    "#data.to_csv('../data/cleaned_labeled_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import nltk\n",
    "import re\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>class_label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retail store manager   alabaster al</td>\n",
       "      <td>0</td>\n",
       "      <td>[retail, store, manager, alabaster, al]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>financial relationship consultant   pell city</td>\n",
       "      <td>0</td>\n",
       "      <td>[financial, relationship, consultant, pell, city]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod cook 3 pm bob's steak   chop</td>\n",
       "      <td>1</td>\n",
       "      <td>[prod, cook, 3, pm, bob, s, steak, chop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quant developer</td>\n",
       "      <td>0</td>\n",
       "      <td>[quant, developer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human resource manager</td>\n",
       "      <td>0</td>\n",
       "      <td>[human, resource, manager]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job_title  class_label  \\\n",
       "0            retail store manager   alabaster al            0   \n",
       "1  financial relationship consultant   pell city            0   \n",
       "2              prod cook 3 pm bob's steak   chop            1   \n",
       "3                                quant developer            0   \n",
       "4                         human resource manager            0   \n",
       "\n",
       "                                              tokens  \n",
       "0            [retail, store, manager, alabaster, al]  \n",
       "1  [financial, relationship, consultant, pell, city]  \n",
       "2           [prod, cook, 3, pm, bob, s, steak, chop]  \n",
       "3                                 [quant, developer]  \n",
       "4                         [human, resource, manager]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "data['tokens'] = data['job_title'].apply(tokenizer.tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the tokens\n",
    "\n",
    "We have several options when representing the tokenized words mathematically:\n",
    "\n",
    "+ Bag of words -- count how many times a word appears \n",
    "+ tf-idf (term frequency-inverse document frequency) - assign weight by relevance of word, not frequency\n",
    "\n",
    "### Processing tools\n",
    "\n",
    "Convert data and target to list format for later use.\n",
    "\n",
    "Define a function to create document-term matrix and fit a vectorizer model. Allow for multiple vectorizer options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# create lists of X and y for later use\n",
    "list_corpus = data['job_title'].tolist()\n",
    "list_labels = data['class_label'].tolist()\n",
    "\n",
    "def fit_vectorizer(data, vec_type='count'):\n",
    "    '''Create and fit a vectorizer\n",
    "    \n",
    "    Options:\n",
    "    + count -> count_vectorizer \n",
    "    + tfidf -> tfidf_vectorizer\n",
    "    \n",
    "    Input:\n",
    "    + data - X data to fit the model\n",
    "    + vec_type - name of vectorizer to use\n",
    "    \n",
    "    Returns:\n",
    "    + Document-term matrix or Tf-idf-weighted document-term matrix\n",
    "    + vectorizer - fitted model\n",
    "    '''\n",
    "    if vec_type=='count':\n",
    "        vectorizer = CountVectorizer()\n",
    "    elif vec_type=='tfidf':\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    else:\n",
    "        print('Please select an appropriate option')\n",
    "    \n",
    "    emb = vectorizer.fit_transform(data)\n",
    "\n",
    "    return emb, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation & Vizualization tools\n",
    "\n",
    "Some functions to help assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='weighted')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='weighted')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def run_skf(df, vec):\n",
    "    '''A training & testing pipeline to compare:\n",
    "    \n",
    "    + Logistic Regression\n",
    "    + Naive Bayes Classification\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    df - pandas dataframe containing labeled data\n",
    "    vec - choice of vectorizer model (count vectorizer or tf-idf)\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    10-fold stratified cross validation results\n",
    "    Various performance metrics\n",
    "    '''\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=0)\n",
    "\n",
    "    X = data['job_title']\n",
    "    y = data['class_label']\n",
    "\n",
    "    current_split = 1\n",
    "\n",
    "    acc_list = []; prec_list = []; rec_list = []\n",
    "    acc_nb = []; prec_nb = []; rec_nb = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        print('CURRENT SPLIT:', current_split)\n",
    "\n",
    "        # get splits & assign data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # vectorize word counts\n",
    "        X_train_counts, count_vectorizer = fit_vectorizer(X_train, vec_type=vec)\n",
    "        X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "        # train & test logsitic regression model\n",
    "        clf = LogisticRegression(C=30.0, class_weight='balanced', solver='newton-cg', \n",
    "                             multi_class='ovr', n_jobs=-1, random_state=40)\n",
    "        clf.fit(X_train_counts, y_train)\n",
    "        y_predicted = clf.predict(X_test_counts)\n",
    "        # check performance\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted)\n",
    "        print(\"LR: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "\n",
    "        # add metrics to list\n",
    "        acc_list.append(accuracy)\n",
    "        prec_list.append(precision)\n",
    "        rec_list.append(recall)\n",
    "\n",
    "        # do the same for Naive bayes\n",
    "        nb_clf = MultinomialNB()\n",
    "        nb_clf.fit(X_train_counts, y_train)\n",
    "        y_pred_nb = nb_clf.predict(X_test_counts)\n",
    "        # check performance\n",
    "        accuracy, precision, recall, f1 = get_metrics(y_test, y_pred_nb)\n",
    "        print(\"NB: accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))\n",
    "        acc_nb.append(accuracy)\n",
    "        prec_nb.append(precision)\n",
    "        rec_nb.append(recall)\n",
    "\n",
    "        current_split += 1\n",
    "\n",
    "    # Sample classification report\n",
    "    cr = classification_report(y_test, y_predicted, labels=[0,1], target_names=['Regular Job', 'Gig'])\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "    print('\\n--- LOGISTIC REGRESSION ---')\n",
    "    print('\\nClassification Report')\n",
    "    print(cr)\n",
    "    print('\\nConfusion Matrix')\n",
    "    print(cm)\n",
    "\n",
    "    # Summarize\n",
    "    print('\\nFinal Perfomance')\n",
    "    print('Accuracy: mean %.3f, variance %.3f' % (np.mean(acc_list), np.var(acc_list)))\n",
    "    print('Precision: mean %.3f, variance %.3f' % (np.mean(prec_list), np.var(prec_list)))\n",
    "    print('Recall: mean %.3f, variance %.3f'% (np.mean(rec_list), np.var(rec_list)))\n",
    "\n",
    "    # nb\n",
    "    cr = classification_report(y_test, y_pred_nb, labels=[0,1], target_names=['Regular Job', 'Gig'])\n",
    "    cm = confusion_matrix(y_test, y_pred_nb)\n",
    "    print('\\n--- NAIVE BAYES CLASSSIFIER ---')\n",
    "    print('\\nClassification Report')\n",
    "    print(cr)\n",
    "    print('\\nConfusion Matrix')\n",
    "    print(cm)\n",
    "\n",
    "    # Summarize\n",
    "    print('\\nFinal Perfomance')\n",
    "    print('Accuracy: mean %.3f, variance %.3f' % (np.mean(acc_nb), np.var(acc_nb)))\n",
    "    print('Precision: mean %.3f, variance %.3f' % (np.mean(prec_nb), np.var(prec_nb)))\n",
    "    print('Recall: mean %.3f, variance %.3f'% (np.mean(rec_nb), np.var(rec_nb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "+ Logistic Regression\n",
    "+ NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SPLIT: 1\n",
      "LR: accuracy = 0.911, precision = 0.910, recall = 0.911, f1 = 0.910\n",
      "NB: accuracy = 0.931, precision = 0.936, recall = 0.931, f1 = 0.925\n",
      "CURRENT SPLIT: 2\n",
      "LR: accuracy = 0.931, precision = 0.932, recall = 0.931, f1 = 0.931\n",
      "NB: accuracy = 0.941, precision = 0.941, recall = 0.941, f1 = 0.938\n",
      "CURRENT SPLIT: 3\n",
      "LR: accuracy = 0.851, precision = 0.849, recall = 0.851, f1 = 0.850\n",
      "NB: accuracy = 0.871, precision = 0.864, recall = 0.871, f1 = 0.865\n",
      "CURRENT SPLIT: 4\n",
      "LR: accuracy = 0.910, precision = 0.916, recall = 0.910, f1 = 0.912\n",
      "NB: accuracy = 0.940, precision = 0.939, recall = 0.940, f1 = 0.939\n",
      "CURRENT SPLIT: 5\n",
      "LR: accuracy = 0.940, precision = 0.940, recall = 0.940, f1 = 0.940\n",
      "NB: accuracy = 0.930, precision = 0.929, recall = 0.930, f1 = 0.929\n",
      "CURRENT SPLIT: 6\n",
      "LR: accuracy = 0.900, precision = 0.897, recall = 0.900, f1 = 0.898\n",
      "NB: accuracy = 0.930, precision = 0.928, recall = 0.930, f1 = 0.928\n",
      "CURRENT SPLIT: 7\n",
      "LR: accuracy = 0.920, precision = 0.924, recall = 0.920, f1 = 0.921\n",
      "NB: accuracy = 0.920, precision = 0.920, recall = 0.920, f1 = 0.920\n",
      "CURRENT SPLIT: 8\n",
      "LR: accuracy = 0.899, precision = 0.933, recall = 0.899, f1 = 0.906\n",
      "NB: accuracy = 0.939, precision = 0.939, recall = 0.939, f1 = 0.939\n",
      "CURRENT SPLIT: 9\n",
      "LR: accuracy = 0.909, precision = 0.911, recall = 0.909, f1 = 0.910\n",
      "NB: accuracy = 0.929, precision = 0.928, recall = 0.929, f1 = 0.927\n",
      "CURRENT SPLIT: 10\n",
      "LR: accuracy = 0.869, precision = 0.884, recall = 0.869, f1 = 0.874\n",
      "NB: accuracy = 0.919, precision = 0.923, recall = 0.919, f1 = 0.921\n",
      "\n",
      "--- LOGISTIC REGRESSION ---\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Regular Job       0.95      0.89      0.92        79\n",
      "        Gig       0.64      0.80      0.71        20\n",
      "\n",
      "avg / total       0.88      0.87      0.87        99\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[70  9]\n",
      " [ 4 16]]\n",
      "\n",
      "Final Perfomance\n",
      "Accuracy: mean 0.904, variance 0.001\n",
      "Precision: mean 0.910, variance 0.001\n",
      "Recall: mean 0.904, variance 0.001\n",
      "\n",
      "--- NAIVE BAYES CLASSSIFIER ---\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Regular Job       0.96      0.94      0.95        79\n",
      "        Gig       0.77      0.85      0.81        20\n",
      "\n",
      "avg / total       0.92      0.92      0.92        99\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[74  5]\n",
      " [ 3 17]]\n",
      "\n",
      "Final Perfomance\n",
      "Accuracy: mean 0.925, variance 0.000\n",
      "Precision: mean 0.925, variance 0.000\n",
      "Recall: mean 0.925, variance 0.000\n"
     ]
    }
   ],
   "source": [
    "run_skf(data, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can see that Naive Bayes seems to work better than Logistic regression. But does this hold? Let's try tf-idf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT SPLIT: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: accuracy = 0.921, precision = 0.919, recall = 0.921, f1 = 0.918\n",
      "NB: accuracy = 0.851, precision = 0.875, recall = 0.851, f1 = 0.817\n",
      "CURRENT SPLIT: 2\n",
      "LR: accuracy = 0.921, precision = 0.924, recall = 0.921, f1 = 0.922\n",
      "NB: accuracy = 0.861, precision = 0.882, recall = 0.861, f1 = 0.832\n",
      "CURRENT SPLIT: 3\n",
      "LR: accuracy = 0.832, precision = 0.835, recall = 0.832, f1 = 0.833\n",
      "NB: accuracy = 0.861, precision = 0.882, recall = 0.861, f1 = 0.832\n",
      "CURRENT SPLIT: 4\n",
      "LR: accuracy = 0.920, precision = 0.929, recall = 0.920, f1 = 0.922\n",
      "NB: accuracy = 0.860, precision = 0.881, recall = 0.860, f1 = 0.831\n",
      "CURRENT SPLIT: 5\n",
      "LR: accuracy = 0.940, precision = 0.940, recall = 0.940, f1 = 0.940\n",
      "NB: accuracy = 0.870, precision = 0.888, recall = 0.870, f1 = 0.846\n",
      "CURRENT SPLIT: 6\n",
      "LR: accuracy = 0.910, precision = 0.909, recall = 0.910, f1 = 0.909\n",
      "NB: accuracy = 0.880, precision = 0.883, recall = 0.880, f1 = 0.865\n",
      "CURRENT SPLIT: 7\n",
      "LR: accuracy = 0.930, precision = 0.931, recall = 0.930, f1 = 0.931\n",
      "NB: accuracy = 0.910, precision = 0.919, recall = 0.910, f1 = 0.900\n",
      "CURRENT SPLIT: 8\n",
      "LR: accuracy = 0.939, precision = 0.953, recall = 0.939, f1 = 0.942\n",
      "NB: accuracy = 0.859, precision = 0.880, recall = 0.859, f1 = 0.826\n",
      "CURRENT SPLIT: 9\n",
      "LR: accuracy = 0.929, precision = 0.928, recall = 0.929, f1 = 0.929\n",
      "NB: accuracy = 0.859, precision = 0.880, recall = 0.859, f1 = 0.826\n",
      "CURRENT SPLIT: 10\n",
      "LR: accuracy = 0.879, precision = 0.890, recall = 0.879, f1 = 0.883\n",
      "NB: accuracy = 0.869, precision = 0.864, recall = 0.869, f1 = 0.853\n",
      "\n",
      "--- LOGISTIC REGRESSION ---\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Regular Job       0.95      0.90      0.92        79\n",
      "        Gig       0.67      0.80      0.73        20\n",
      "\n",
      "avg / total       0.89      0.88      0.88        99\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[71  8]\n",
      " [ 4 16]]\n",
      "\n",
      "Final Perfomance\n",
      "Accuracy: mean 0.912, variance 0.001\n",
      "Precision: mean 0.916, variance 0.001\n",
      "Recall: mean 0.912, variance 0.001\n",
      "\n",
      "--- NAIVE BAYES CLASSSIFIER ---\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Regular Job       0.88      0.97      0.92        79\n",
      "        Gig       0.82      0.45      0.58        20\n",
      "\n",
      "avg / total       0.86      0.87      0.85        99\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[77  2]\n",
      " [11  9]]\n",
      "\n",
      "Final Perfomance\n",
      "Accuracy: mean 0.868, variance 0.000\n",
      "Precision: mean 0.883, variance 0.000\n",
      "Recall: mean 0.868, variance 0.000\n"
     ]
    }
   ],
   "source": [
    "run_skf(data, 'tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Naive Bayes ourperforms Logistic Regression with a basic Bag of Words model, its performance, especially with regards to the recall of the underrepresented classs drops off when using Tf-idf.\n",
    "\n",
    "Still, the performance of Naive Bayes + Bag of words remains better than Logistic Regression + Tf-idf (which improved from Bag of Words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "It appears from this trial, both Naive Bayes and Logsitic regression perform well on our data. \n",
    "\n",
    "Naive Bayes is particularly promising, owing it it's simplicity and ease of additional training/modification. Naive Bayes is particularly attractive as it is extensible to labeling multiple classes and its ability to continue incorporating new training samples to an existing model. \n",
    "\n",
    "Moving forward, as we seek to classify more than just skilled & gig positions, Naive Bayes should be considered.\n",
    "\n",
    "It should be noted, however, that due to the small size of training data currently available, it is premature to decide whether one classifier is clearly outperforming the rest. Therefore, both Logistic Regression and Naive Bayes should be re-evaluated as more data becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
